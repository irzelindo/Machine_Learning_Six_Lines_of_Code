{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing scikit learn datasets\n",
    "- The `sklearn.datasets` module includes utilities to load datasets, including methods to load and fetch popular reference datasets. It also features some artificial data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the ‘real world’. **load_iris** was used here. \n",
    "\n",
    "- It’s also possible for almost all of these functions to constrain the output to be a tuple containing only the **data(features=X)** and the **target(labels=y)**, by setting the `return_X_y` parameter to `True`.\n",
    "\n",
    "- In line[2] below,a **tuple** containing both data(features) and target(labels) of the **iris** dataset is returned `X, y = datasets.load_iris(return_X_y=True)`, the only difference is that this time, we're not loading the entire dataset metadata as we did on the episode #2;\n",
    "- **Note:** In Python, elements of tuples and lists can be assigned to multiple variables. It is called **sequence unpacking.** For our specific case **Tuple Unpacking.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In line[3], we can clearly see that this time no extra exercise was required to split our dataset into training and testing subsets.\n",
    "- Just by importing the `train_test_split` function from `sklearn.model_selection` we could quickly get our data split into four(4) shuffled datasets. the `train_test_split()` function must take the **data(features), target(labels) subsets** if test_size is not defined a default value of .25 will be used. which stands for 25%. In our case we've defined .5 or 50% for splitting and shuffling our dataset. **50% of 150 records 75 lines**\n",
    "- `train_test_split()` **returns: list, length=2 * len(arrays)** in our case(*we provided two(2) arrays, X and y*), four(4) arrays will be returned, 50% for training, 50% for testing. `X_train, X_test, y_train, y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's always a good practice to visualize the datasets before starting to analyze it;\n",
    "- In line[4], I'm just printing the datasets shapes and preview data to ensure all is fine;\n",
    "- The **Iris** dataset table is composed of four(4) columns of features (sepal length, sepal width, petal length, petal width) and one list containing the type of iris flowers (Setosa, Versicolor, and Virginica). That's why the features dataset are 75 lines by 4 columns while the labels are only 75 lines. \n",
    "- **X_train** - Features(data);\n",
    "- **y_train** - Labels(target);\n",
    "- **X_test** - Test data (features);\n",
    "- **y_test** - Test labels (target) to check how accurate our classifier is, by comparing it with correct predicted **X_test** inputs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 4) (75,) (75, 4) (75,) \n",
      "\n",
      "[6.1 2.8 4.7 1.2] 1 [5.7 2.8 4.1 1.3] 1\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, \"\\n\")\n",
    "\n",
    "print(X_train[0], y_train[0], X_test[0], y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (sklearn.neighbors)[https://scikit-learn.org/stable/modules/neighbors.html?highlight=knn%20classification#nearest-neighbors] provides functionality for unsupervised and supervised neighbors-based learning methods. Unsupervised nearest neighbors is the foundation of many other learning methods, notably manifold learning and spectral clustering. Supervised neighbors-based learning comes in two flavors: classification for data with discrete labels, and regression for data with continuous labels.\n",
    "- We'll benefit of the **KNeighborsClassifier** for this exercise, we can tell by the shape of our data that we're dealing with a classification problem. **(discrete labels data composed by three flower species)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.66666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.66666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, y_test) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
