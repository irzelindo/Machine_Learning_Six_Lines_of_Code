{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing scikit learn datasets\n",
    "- The `sklearn.datasets` module includes utilities to load datasets, including methods to load and fetch popular reference datasets. It also features some artificial data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the ‘real world’. **load_iris** was used here. \n",
    "\n",
    "- It’s also possible for almost all of these functions to constrain the output to be a tuple containing only the **data(features=X)** and the **target(labels=y)**, by setting the `return_X_y` parameter to `True`.\n",
    "\n",
    "- In line[2] below,a **tuple** containing both data(features) and target(labels) of the **iris** dataset is returned `X, y = datasets.load_iris(return_X_y=True)`, the only difference is that this time, we're not loading the entire dataset metadata as we did on the episode #2;\n",
    "- **Note:** In Python, elements of tuples and lists can be assigned to multiple variables. It is called **sequence unpacking.** For our specific case **Tuple Unpacking.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In line[3], we can clearly see that this time no extra exercise was required to split our dataset into training and testing subsets.\n",
    "- Just by importing the `train_test_split` function from `sklearn.model_selection` we could quickly get our data split into four(4) shuffled datasets. the `train_test_split()` function must take the **data(features), target(labels)** subsets, if test_size is not defined a default value of .25 will be used. which stands for 25% of the dataset data. In our case we've defined .5 or 50% for splitting and shuffling our dataset. **50% of 150 records is 75 records or lines of our dataframe**\n",
    "- `train_test_split()` **returns: list, length=2 * len(arrays)** in our case(*we provided two(2) arrays, X and y*), four(4) arrays will be returned, 50% for training, 50% for testing. `X_train, X_test, y_train, y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's always a good practice to visualize the data before starting to analyze it;\n",
    "- In line[4], I'm just printing the datasets shapes and preview data to ensure all is fine;\n",
    "- The **Iris** dataset table is composed of five(5) columns, four(4) columns of features (sepal length, sepal width, petal length, petal width) and one(1) last column containing the specie of the iris flower(Setosa, Versicolor, and Virginica). \n",
    "- **X_train** - Features(data);\n",
    "- **y_train** - Labels(target);\n",
    "- **X_test** - Test data (features);\n",
    "- **y_test** - Test labels (target) to check how accurate our classifier is, by comparing it with correct predicted **X_test** inputs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 4) (75,) (75, 4) (75,) \n",
      "\n",
      "Train feature [6.3 2.7 4.9 1.8], Train label 2, Test feature [4.9 2.4 3.3 1. ], Test lable 1\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, \"\\n\")\n",
    "\n",
    "print(f\"Train feature {X_train[0]}, Train label {y_train[0]}, Test feature {X_test[0]}, Test lable {y_test[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [sklearn.neighbors](https://scikit-learn.org/stable/modules/neighbors.html?highlight=knn%20classification#nearest-neighbors) provides functionality for unsupervised and supervised neighbors-based learning methods. Unsupervised nearest neighbors is the foundation of many other learning methods, notably manifold learning and spectral clustering. Supervised neighbors-based learning comes in two flavors: classification for data with discrete labels, and regression for data with continuous labels.\n",
    "\n",
    "- This time instead of the  `KNeighborsClassifier` from the `sklearn.neighbors` we'll test our own classifier the `testKNN classifier`, we can tell by the shape of our data that we're dealing with a classification problem. **(discrete labels data composed by three flower species)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testKNN import testKNN\n",
    "\n",
    "clf = testKNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In line[6] We fit/train the model using **X_train** as training data and **y_train** as target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remember the **X_test** we got from the `train_test_split()` function on line[3]?\n",
    "* We'll benefit from that unknown subset data to check how accurate the classifier is, in line[7] we call the `predict()` function inside the classifier object to predict the unknown data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The classifier object also provides the `score()` function to help us check in percentual terms how accurate our classifier is on predicting data that was never seen before.\n",
    "\n",
    "* `score()` Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "* In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The same result can be achieved by using the `accuracy_score` from the `sklearn.metrics` package. \n",
    "\n",
    "* Note: The result is in 0 - 1 Real number range, that's why a multiplication by 100 was required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, y_test) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
